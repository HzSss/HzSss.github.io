{"title":"操作系统学习笔记","slug":"操作系统学习笔记","date":"2018-09-25T10:25:43.000Z","updated":"2018-09-26T02:41:59.783Z","comments":true,"excerpt":"","content":"<h3 id=\"第一章-操作系统引论\"><a href=\"#第一章-操作系统引论\" class=\"headerlink\" title=\"第一章 操作系统引论\"></a>第一章 操作系统引论</h3><h4 id=\"1-1-操作系统的目标和作用\"><a href=\"#1-1-操作系统的目标和作用\" class=\"headerlink\" title=\"1.1 操作系统的目标和作用\"></a>1.1 操作系统的目标和作用</h4><h5 id=\"1-1-1-操作系统的目标\"><a href=\"#1-1-1-操作系统的目标\" class=\"headerlink\" title=\"1.1.1 操作系统的目标\"></a>1.1.1 操作系统的目标</h5><ol>\n<li>有效性</li>\n</ol>\n<p>操作系统的有效性可包含如下两方面的含意：</p>\n<p>(1) 提高系统资源利用率。配置了 OS 之后，可使 CPU 和 I/O 设备由于能保持忙碌状态而得到有效的利用，且可使内存和外存中存放的数据因有序而节省了存储空间。</p>\n<p>(2) 提高系统的吞吐量。操作系统还可以通过合理地组织计算机的工作流程，而进一步改善资源的利用率，加速程序的运行，缩短程序的运行周期，从而提高系统的吞吐量。</p>\n<ol start=\"2\">\n<li>方便性</li>\n</ol>\n<p>配置 OS 后可使计算机系统更容易使用。</p>\n<ol start=\"3\">\n<li>可扩充性</li>\n</ol>\n<p>OS 必须具有很好的可扩充性，方能适应计算机硬件、体系结构以及应用发展的要求。</p>\n<ol start=\"4\">\n<li>开放性</li>\n</ol>\n<p>为使来自不同厂家的计算机和设备能通过网络加以集成化，并能正确、有效地协同工作，实现应用的可移植性和互操作性，要求操作系统必须提供统一的开放环境，进而要求 OS 具有开放性。</p>\n<p>开放性是指系统能遵循世界标准规范，特别是遵循开放系统互连(OSI)国际标准。凡遵循国际标准所开发的硬件和软件，均能彼此兼容，可方便地实现互连。</p>\n<h5 id=\"1-1-2-操作系统的作用\"><a href=\"#1-1-2-操作系统的作用\" class=\"headerlink\" title=\"1.1.2 操作系统的作用\"></a>1.1.2 操作系统的作用</h5><ol>\n<li>OS 作为用户与计算机硬件系统之间的接口</li>\n</ol>\n<p>OS 作为用户与计算机硬件系统之间接口的含义是：OS 处于用户与计算机硬件系统之间，用户通过 OS 来使用计算机系统。或者说，用户在 OS 帮助下，能够方便、快捷、安全、可靠地操纵计算机硬件和运行自己的程序。</p>\n<p>用户可通过以下三种方式使用计算机：</p>\n<p>(1) 命令方式。这是指由 OS 提供了一组联机命令接口，以允许用户通过键盘输入有关命令来取得操作系统的服务，并控制用户程序的运行。</p>\n<p>(2) 系统调用方式。OS 提供了一组系统调用，用户可在自己的应用程序中通过相应的系统调用，来实现与操作系统的通信，并取得它的服务。</p>\n<p>(3) 图形、窗口方式。这是当前使用最为方便、最为广泛的接口，它允许用户通过屏幕上的窗口和图标来实现与操作系统的通信，并取得它的服务。<br><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p480\" alt=\"c86b76b4228b1a2c1f71d858298ba8b7.png\"></p>\n<ol start=\"2\">\n<li>OS 作为计算机系统资源的管理者</li>\n</ol>\n<p>在一个计算机系统中，通常都含有各种各样的硬件和软件资源。归纳起来可将资源分为四类：处理器、存储器、I/O 设备以及信息(数据和程序)。</p>\n<p>(1) 处理机管理，用于分配和控制处理机；</p>\n<p>(2) 存储器管理，主要负责内存的分配与回收；</p>\n<p>(3) I/O 设备管理，负责 I/O 设备的分配与操纵；</p>\n<p>(4) 文件管理，负责文件的存取、共享和保护。</p>\n<ol start=\"3\">\n<li>OS 实现了对计算机资源的抽象</li>\n</ol>\n<p>OS 是铺设在计算机硬件上的多层系统软件，它们不仅增强了系统的功能，而且还隐藏了对硬件操作的细节，由它们实现了对计算机硬件操作的多个层次的抽象。</p>\n<p><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p481\" alt=\"ccdd6db7655087d30900a7dfdc746ba1.png\"></p>\n<h4 id=\"1-2-操作系统的发展过程\"><a href=\"#1-2-操作系统的发展过程\" class=\"headerlink\" title=\"1.2 操作系统的发展过程\"></a>1.2 操作系统的发展过程</h4><h5 id=\"1-2-1-无操作系统的计算机系统\"><a href=\"#1-2-1-无操作系统的计算机系统\" class=\"headerlink\" title=\"1.2.1 无操作系统的计算机系统\"></a>1.2.1 无操作系统的计算机系统</h5><h5 id=\"1-2-2-单道批处理系统\"><a href=\"#1-2-2-单道批处理系统\" class=\"headerlink\" title=\"1.2.2 单道批处理系统\"></a>1.2.2 单道批处理系统</h5><ol>\n<li>单道批处理系统的处理过程</li>\n</ol>\n<p>其自动处理过程是：首先，由监督程序将磁带上的第一个作业装入内存，并把运行控制权交给该作业。当该作业处理完成时，又把控制权交还给监督程序，再由监督程序把磁带(盘)上的第二个作业调入内存。计算机系统就这样自动地一个作业一个作业地进行处理，直至磁带(盘)上的所有作业全部完成，这样便形成了早期的批处理系统。由于系统对作业的处理都是成批地进行的，且在内存中始终只保持一道作业，故称此系统为单道批处理系统(Simple Batch Processing System)。</p>\n<p><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p482\" alt=\"e7ffbe05c4bdfe4e212de0fd72a07636.png\"></p>\n<ol start=\"2\">\n<li>单道批处理系统的特征</li>\n</ol>\n<p>(1) 自动性。在顺利情况下，在磁带上的一批作业能自动地逐个地依次运行，而无需人工预。</p>\n<p>(2) 顺序性。磁带上的各道作业是顺序地进入内存，各道作业的完成顺序与它们进入内存的顺序，在正常情况下应完全相同，亦即先调入内存的作业先完成。</p>\n<p>(3) 单道性。内存中仅有一道程序运行，即监督程序每次从磁带上只调入一道程序进入内存运行，当该程序完成或发生异常情况时，才换入其后继程序进入内存运行。</p>\n<h5 id=\"1-2-3-多道批处理系统\"><a href=\"#1-2-3-多道批处理系统\" class=\"headerlink\" title=\"1.2.3 多道批处理系统\"></a>1.2.3 多道批处理系统</h5><ol>\n<li>多道批处理系统的基本概念</li>\n</ol>\n<p>在引入多道程序设计技术后，由于同时在内存中装有若干道程序，并使它们交替地运行，这样，当正在运行的程序因 I/O 而暂停执行时，系统可调度另一道程序运行，从而保持了 CPU 处于忙碌状态。</p>\n<p>宏观上并行：同时进入系统的多道程序都处于运行过程中，即它们先后开始了各自的运行，但都未运行完毕。</p>\n<p>微观上串行：内存中的多道程序轮流占有 CPU，交替执行。</p>\n<ol start=\"2\">\n<li>多道批处理系统的优点</li>\n</ol>\n<p>(1) 提高 CPU 的利用率。</p>\n<p>(2) 可提高内存和 I/O 设备利用率。许在内存中装入多道程序，并允许它们并发执行，则无疑会大大提高内存和 I/O 设备的利用率。</p>\n<p>(3) 增加系统吞吐量。在保持 CPU、I/O 设备不断忙碌的同时，也必然会大幅度地提高系统的吞吐量，从而降低作业加工所需的费用。</p>\n<ol start=\"3\">\n<li>多道批处理系统的优点</li>\n</ol>\n<p>(1) 平均周转时间长。在批处理系统中，由于作业要排队，依次进行处理，因而作业的周转时间较长，通常需几个小时，甚至几天</p>\n<p>(2) 无交互能力。用户一旦把作业提交给系统后，直至作业完成，用户都不能与自己的作业进行交互，这对修改和调试程序是极不方便的。</p>\n<h5 id=\"1-2-4-分时系统\"><a href=\"#1-2-4-分时系统\" class=\"headerlink\" title=\"1.2.4 分时系统\"></a>1.2.4 分时系统</h5><ol>\n<li>分时系统的概念</li>\n</ol>\n<p>在操作系统中釆用分时技术就形成了分时系统。所谓分时技术就是把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用。若某个作业在分配给它的时间片内不能完成其计算，则该作业暂时停止运行，把处理器让给其他作业使用，等待下一轮再继续运行。由于计算机速度很快，作业运行轮转得很快，给每个用户的感觉好像是自己独占一台计算机。</p>\n<ol start=\"2\">\n<li>分时系统的特征</li>\n</ol>\n<p>(1) 多路性。允许在一台主机上同时联接多台联机终端，系统按分时原则为每个用户服务。宏观上，是多个用户同时工作，共享系统资源；而微观上，则是每个用户作业轮流运行一个时间片。多路性即同时性，它提高了资源利用率，降低了使用费用，从而促进了计算机更广泛的应用。</p>\n<p>(2) 独立性。每个用户各占一个终端，彼此独立操作，互不干扰。因此，用户所感觉到的，就像是他一人独占主机。</p>\n<p>(3) 及时性。用户的请求能在很短的时间内获得响应。此时间间隔是以人们所能接受的等待时间来确定的，通常仅为 1～3 秒钟。</p>\n<p>(4) 交互性。用户可通过终端与系统进行广泛的人机对话。其广泛性表现在：用户可以请求系统提供多方面的服务，如文件编辑、数据处理和资源共享等。</p>\n<h5 id=\"1-2-5-实时系统\"><a href=\"#1-2-5-实时系统\" class=\"headerlink\" title=\"1.2.5 实时系统\"></a>1.2.5 实时系统</h5><p>所谓“实时”，是表示“及时”，而实时系统(Real Time System)是指系统能及时(或即时)<br>响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一<br>致地运行。</p>\n<h5 id=\"1-2-6-微机操作系统的发展\"><a href=\"#1-2-6-微机操作系统的发展\" class=\"headerlink\" title=\"1.2.6 微机操作系统的发展\"></a>1.2.6 微机操作系统的发展</h5><p>配置在微型机上的操作系统称为微机操作系统。</p>\n<ol>\n<li>单用户单任务操作系统</li>\n</ol>\n<p>单用户单任务操作系统的含义是，只允许一个用户上机，且只允许用户程序作为一个任务运行。最有代表性的单用户单任务微机操作系统是 CP/M 和 MS-DOS。</p>\n<ol start=\"2\">\n<li>单用户多任务操作系统</li>\n</ol>\n<p>单用户多任务操作系统的含义是，只允许一个用户上机，但允许用户把程序分为若干个任务，使它们并发执行，从而有效地改善了系统的性能。目前在 32 位微机上配置的操作系统基本上都是单用户多任务操作系统，其中最有代表性的是由微软公司推出的 Windows。</p>\n<ol start=\"3\">\n<li>多用户多任务操作系统</li>\n</ol>\n<p>多用户多任务操作系统的含义是，允许多个用户通过各自的终端使用同一台机器，共享主机系统中的各种资源，而每个用户程序又可进一步分为几个任务，使它们能并发执行，从而可进一步提高资源利用率和系统吞吐量。</p>\n<p>其中最有代表性的是 UNIX OS。现在最有影响的两个能运行在微机上的 UNIX 操作系统的变型是 Solaris OS 和 Linux OS。</p>\n<h4 id=\"1-3-操作系统的基本特性\"><a href=\"#1-3-操作系统的基本特性\" class=\"headerlink\" title=\"1.3 操作系统的基本特性\"></a>1.3 操作系统的基本特性</h4><h5 id=\"1-3-1-并发性\"><a href=\"#1-3-1-并发性\" class=\"headerlink\" title=\"1.3.1 并发性\"></a>1.3.1 并发性</h5><ol>\n<li>并行与并发</li>\n</ol>\n<p>并行性和并发性(Concurrence)是既相似又有区别的两个概念，并行性是指两个或多个事件在同一时刻发生；而并发性是指两个或多个事件在同一时间间隔内发生。</p>\n<p>在多道程序环境下，并发性是指在一段时间内宏观上有多个程序在同时运行，但在单处理机系统中，每一时刻却仅能有一道程序执行，故微观上这些程序只能是分时地交替执行。</p>\n<p>倘若在计算机系统中有多个处理机，则这些可以并发执行的程序便可被分配到多个处理机上，实现并行执行，即利用每个处理机来处理一个可并发执行的程序，这样，多个程序便可同时执行。</p>\n<ol start=\"2\">\n<li>引入进程</li>\n</ol>\n<p>应当指出，通常的程序是静态实体(Passive Entity)，在多道程序系统中，它们是不能独立运行的，更不能和其它程序并发执行。在操作系统中引入进程的目的，就是为了使多个程序能并发执行。</p>\n<p>为使多个程序能并发执行，系统必须分别为每个程序建立进程(Process)。简单说来，进程是指在系统中能独立运行并作为资源分配的基本单位，它是由一组机器指令、数据和堆栈等组成的，是一个能独立运行的活动实体。多个进程之间可以并发执行和交换信息。一个进程在运行时需要一定的资源，如 CPU、存储空间及 I/O 设备等。</p>\n<ol start=\"3\">\n<li>引入线程</li>\n</ol>\n<p>通常在一个进程中可以包含若干个线程，它们可以利用进程所拥有的资源。在引入线程的 OS 中，通常都是把进程作为分配资源的基本单位，而把线程作为独立运行和独立调度的基本单位。</p>\n<h5 id=\"1-3-2-共享性\"><a href=\"#1-3-2-共享性\" class=\"headerlink\" title=\"1.3.2 共享性\"></a>1.3.2 共享性</h5><p>在操作系统环境下，所谓共享(Sharing)，是指系统中的资源可供内存中多个并发执行的进程(线程)共同使用，相应地，把这种资源共同使用称为资源共享，或称为资源复用。</p>\n<ol>\n<li>互斥共享方式</li>\n</ol>\n<p>系统中的某些资源，如打印机、磁带机，虽然它们可以提供给多个进程(线程)使用，但为使所打印或记录的结果不致造成混淆，应规定在一段时间内只允许一个进程(线程)访问该资源。为此，系统中应建立一种机制，以保证对这类资源的互斥访问。</p>\n<p>为此，系统中应建立一种机制，以保证对这类资源的互斥访问。当一个进程 A 要访问某资源时，必须先提出请求。如果此时该资源空闲，系统便可将之分配给请求进程 A 使用。此后若再有其它进程也要访问该资源时(只要 A 未用完)，则必须等待。仅当 A 进程访问完并释放该资源后，才允许另一进程对该资源进行访问。</p>\n<p>我们把这种资源共享方式称为互斥式共享，而把在一段时间内只允许一个进程访问的资源称为临界资源或独占资源。计算机系统中的大多数物理设备，以及某些软件中所用的栈、变量和表格，都属于临界资源，它们要求被互斥地共享。为此，在系统中必需配置某种机制来保证诸进程互斥地使用独占资源。</p>\n<p>临界资源是定义在共享资源上的，临界资源一定是共享资源。</p>\n<ol start=\"2\">\n<li>同时共享方式</li>\n</ol>\n<p>系统中还有另一类资源，允许在一段时间内由多个进程“同时”对它们进行访问。这里所谓的“同时”，在单处理机环境下往往是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问。典型的可供多个进程“同时”访问的资源是磁盘设备，一些用重入码编写的文件也可以被“同时”共享，即若干个用户同时访问该文件。</p>\n<h5 id=\"虚拟性\"><a href=\"#虚拟性\" class=\"headerlink\" title=\"虚拟性\"></a>虚拟性</h5><ol>\n<li>时分复用技术</li>\n</ol>\n<p>在虚拟处理机技术中，利用多道程序设计技术，为每道程序建立一个进程，让多道程序并发地执行，以此来分时使用一台处理机。此时，虽然系统中只有一台处理机，但它却能同时为多个用户服务，使每个终端用户都认为是有一个处理机在专门为他服务。</p>\n<ol start=\"2\">\n<li>空分复用技术</li>\n</ol>\n<p>如果说时分复用技术是利用处理机的空闲时间来运行其它的程序，使处理机的利用率得以提高，那么空分复用则是利用存储器的空闲空间来存放其它的程序，以提高内存的利用率。</p>\n<h5 id=\"1-3-4-异步性\"><a href=\"#1-3-4-异步性\" class=\"headerlink\" title=\"1.3.4 异步性\"></a>1.3.4 异步性</h5><p>进程是以人们不可预知的速度向前推进，此即进程的异步性(Asynchronism)。</p>\n<h4 id=\"1-4-操作系统的主要功能\"><a href=\"#1-4-操作系统的主要功能\" class=\"headerlink\" title=\"1.4 操作系统的主要功能\"></a>1.4 操作系统的主要功能</h4><h5 id=\"1-4-1-处理机管理功能\"><a href=\"#1-4-1-处理机管理功能\" class=\"headerlink\" title=\"1.4.1 处理机管理功能\"></a>1.4.1 处理机管理功能</h5><ol>\n<li>进程控制</li>\n</ol>\n<p>进程控制的主要功能是为作业创建进程，撤消已结束的进程，以及控制进程在运行过程中的状态转换。在现代 OS 中，进程控制还应具有为一个进程创建若干个线程的功能和撤消(终止)已完成任务的线程的功能。</p>\n<ol start=\"2\">\n<li>进程同步</li>\n</ol>\n<p>前已述及，进程是以异步方式运行的，并以人们不可预知的速度向前推进。为使多个进程能有条不紊地运行，系统中必须设置进程同步机制。</p>\n<p>(1) 进程互斥方式。这是指诸进程(线程)在对临界资源进行访问时，应采用互斥方式；</p>\n<p>(2) 进程同步方式。这是指在相互合作去完成共同任务的诸进程(线程)间，由同步机构对它们的执行次序加以协调。</p>\n<ol start=\"3\">\n<li>进程通信</li>\n</ol>\n<p>当相互合作的进程(线程)处于同一计算机系统时，通常在它们之间是采用直接通信方式，即由源进程利用发送命令直接将消息(Message)挂到目标进程的消息队列上，以后由目标进程利用接收命令从其消息队列中取出消息。</p>\n<ol start=\"4\">\n<li>调度</li>\n</ol>\n<p>在后备队列上等待的每个作业都需经过调度才能执行。在传统的操作系统中，包括作业调度和进程调度两步。</p>\n<h5 id=\"1-4-2-存储器管理功能\"><a href=\"#1-4-2-存储器管理功能\" class=\"headerlink\" title=\"1.4.2 存储器管理功能\"></a>1.4.2 存储器管理功能</h5><ol>\n<li>内存分配</li>\n</ol>\n<p>内存分配的主要任务是为每道程序分配内存空间，使它们“各得其所”；提高存储器的利用率，以减少不可用的内存空间；允许正在运行的程序申请附加的内存空间，以适应程序和数据动态增长的需要。</p>\n<ol start=\"2\">\n<li>内存保护</li>\n</ol>\n<p>内存保护的主要任务是确保每道用户程序都只在自己的内存空间内运行，彼此互不干扰；绝不允许用户程序访问操作系统的程序和数据；也不允许用户程序转移到非共享的其它用户程序中去执行。</p>\n<ol start=\"3\">\n<li>地址映射</li>\n</ol>\n<p>为使程序能正确运行，存储器管理必须提供地址映射功能，以将地址空间中的逻辑地址转换为内存空间中与之对应的物理地址。该功能应在硬件的支持下完成。</p>\n<ol start=\"4\">\n<li>内存扩充</li>\n</ol>\n<p>存储器管理中的内存扩充任务并非是去扩大物理内存的容量，而是借助于虚拟存储技术，从逻辑上去扩充内存容量，使用户所感觉到的内存容量比实际内存容量大得多，以便让更多的用户程序并发运行。</p>\n<p>(1) 请求调入功能。允许在装入一部分用户程序和数据的情况下，便能启动该程序运行。在程序运行过程中，若发现要继续运行时所需的程序和数据尚未装入内存，可向 OS 发出请求，由 OS 从磁盘中将所需部分调入内存，以便继续运行。</p>\n<p>(2) 置换功能。若发现在内存中已无足够的空间来装入需要调入的程序和数据时，系统应能将内存中的一部分暂时不用的程序和数据调至盘上，以腾出内存空间，然后再将所需调入的部分装入内存。</p>\n<h5 id=\"1-4-3-设备管理功能\"><a href=\"#1-4-3-设备管理功能\" class=\"headerlink\" title=\"1.4.3 设备管理功能\"></a>1.4.3 设备管理功能</h5><p>设备管理用于管理计算机系统中所有的外围设备，而设备管理的主要任务是：完成用户进程提出的 I/O 请求；为用户进程分配其所需的 I/O 设备；提高 CPU 和 I/O 设备的利用率；提高I/O 速度；方便用户使用 I/O 设备。</p>\n<ol>\n<li>缓冲功能</li>\n</ol>\n<p>CPU 运行的高速性和 I/O 低速性间的矛盾自计算机诞生时起便已存在了。如果在 I/O 设备和 CPU之间引入缓冲，则可有效地缓和 CPU 与 I/O 设备速度不匹配的矛盾，提高 CPU 的利用率，进而提高系统吞吐量。提高 CPU 与设备之间的并行程度。</p>\n<ol start=\"2\">\n<li>设备分配</li>\n</ol>\n<p>设备分配的基本任务是根据用户进程的 I/O 请求、系统的现有资源情况以及按照某种设备的分配策略，为之分配其所需的设备。</p>\n<ol start=\"3\">\n<li>设备处理</li>\n</ol>\n<p>设备处理程序又称为设备驱动程序。其基本任务是用于实现 CPU 和设备控制器之间的通信，即由 CPU 向设备控制器发出 I/O 命令，要求它完成指定的 I/O 操作；反之，由 CPU 接收从控制器发来的中断请求，并给予迅速的响应和相应的处理。</p>\n<h5 id=\"1-4-4-文件管理功能\"><a href=\"#1-4-4-文件管理功能\" class=\"headerlink\" title=\"1.4.4 文件管理功能\"></a>1.4.4 文件管理功能</h5><ol>\n<li>文件存储空间的管理</li>\n</ol>\n<p>系统应设置相应的数据结构，用于记录文件存储空间的使用情况，以供分配存储空间时参考；系统还应具有对存储空间进行分配和回收的功能。为了提高存储空间的利用率，对存储空间的分配，通常是采用离散分配方式，以减少外存零头，并以盘块为基本分配单位。盘块的大小通常为 1～8 KB。</p>\n<ol start=\"2\">\n<li>目录管理</li>\n</ol>\n<p>为了使用户能方便地在外存上找到自己所需的文件，通常由系统为每个文件建立一个目录项。目录项包括文件名、文件属性、文件在磁盘上的物理位置等。由若干个目录项又可构成一个目录文件。其次，目录管理还应能实现文件共享，这样，只须在外存上保留一份该共享文件的副本。此外，还应能提供快速的目录查询手段，以提高对文件的检索速度。</p>\n<ol start=\"3\">\n<li>文件的读/写管理和保护</li>\n</ol>\n<h5 id=\"1-4-5-操作系统与用户之间的接口\"><a href=\"#1-4-5-操作系统与用户之间的接口\" class=\"headerlink\" title=\"1.4.5 操作系统与用户之间的接口\"></a>1.4.5 操作系统与用户之间的接口</h5><ol>\n<li>用户接口</li>\n</ol>\n<p>它是提供给用户使用的接口，用户可通过该接口取得操作系统的服务；</p>\n<ol start=\"2\">\n<li>程序接口</li>\n</ol>\n<p>它是提供给程序员在编程时使用的接口，是用户程序取得操作系统服务的惟一途径。</p>\n<h4 id=\"1-5\"><a href=\"#1-5\" class=\"headerlink\" title=\"1.5\"></a>1.5</h4><h5 id=\"1-5-1-微内核-OS-结构\"><a href=\"#1-5-1-微内核-OS-结构\" class=\"headerlink\" title=\"1.5.1 微内核 OS 结构\"></a>1.5.1 微内核 OS 结构</h5><ol>\n<li>微内核操作系统的优点</li>\n</ol>\n<p>(1) 提高了系统的可扩展性</p>\n<p>(2) 增强了系统的可靠性</p>\n<p>(3) 可移植性</p>\n<p>(4) 提供了对分布式系统的支持</p>\n<p>(5) 融入了面向对象技术</p>\n<ol start=\"2\">\n<li>微内核操作系统存在的问题</li>\n</ol>\n<p>微内核 OS 的运行效率有所降低。效率降低的最主要的原因是，在完成一次客户对 OS 提出的服务请求时，需要利用消息实现多次交互和进行用户/内核模式及上下文的多次切换。</p>\n<h3 id=\"第二章-进程管理\"><a href=\"#第二章-进程管理\" class=\"headerlink\" title=\"第二章 进程管理\"></a>第二章 进程管理</h3><h4 id=\"2-1-进程的基本概念\"><a href=\"#2-1-进程的基本概念\" class=\"headerlink\" title=\"2.1 进程的基本概念\"></a>2.1 进程的基本概念</h4><h5 id=\"2-1-1-程序的顺序执行及其特征\"><a href=\"#2-1-1-程序的顺序执行及其特征\" class=\"headerlink\" title=\"2.1.1 程序的顺序执行及其特征\"></a>2.1.1 程序的顺序执行及其特征</h5><ol>\n<li>程序顺序执行时的特征</li>\n</ol>\n<p>(1) 顺序性：处理机的操作严格按照程序所规定的顺序执行，即每一操作必须在上一个操作结束之后开始。</p>\n<p>(2) 封闭性：程序是在封闭的环境下执行的，即程序运行时独占全机资源，资源的状态(除初始状态外)只有本程序才能改变它。程序一旦开始执行，其执行结果不受外界因素影响。</p>\n<p>(3) 可再现性：只要程序执行时的环境和初始条件相同，当程序重复执行时，不论它是从头到尾不停顿地执行，还是“停停走走”地执行，都将获得相同的结果。</p>\n<h5 id=\"2-1-2-程序的并发执行及其特征\"><a href=\"#2-1-2-程序的并发执行及其特征\" class=\"headerlink\" title=\"2.1.2 程序的并发执行及其特征\"></a>2.1.2 程序的并发执行及其特征</h5><ol>\n<li>程序的并发执行时的特征</li>\n</ol>\n<p>(1) 间断性：程序在并发执行时，由于它们共享系统资源，以及为完成同一项任务而相互合作，致使在这些并发执行的程序之间，形成了相互制约的关系。</p>\n<p>(2) 失去封闭性：程序在并发执行时，是多个程序共享系统中的各种资源，因而这些资源的状态将由多个程序来改变，致使程序的运行失去了封闭性。这样，某程序在执行时，必然会受到其它程序的影响。例如，当处理机这一资源已被某个程序占有时，另一程序必须等待。</p>\n<p>(3) 不可再现性：程序在并发执行时，由于失去了封闭性，也将导致其再失去可再现性。程序经过多次执行后，虽然它们执行时的环境和初始条件相同，但得到的结果却各不相同。</p>\n<h5 id=\"2-1-3-进程的特征与状态\"><a href=\"#2-1-3-进程的特征与状态\" class=\"headerlink\" title=\"2.1.3 进程的特征与状态\"></a>2.1.3 进程的特征与状态</h5><ol>\n<li>进程的特征和定义</li>\n</ol>\n<p>为使程序能并发执行，且为了对并发执行的程序加以描述和控制，人们引入了“进程”的概念。下面对进程的特征加以描述。</p>\n<p>(1) 结构特征：</p>\n<p>通常的程序是不能并发执行的。为使程序(含数据)能独立运行，应为之配置一进程控制块，即 PCB(Process Control Block)；而由程序段、相关的数据段和 PCB三部分便构成了进程实体。在早期的 UNIX 版本中，把这三部分总称为“进程映像”。值得指出的是，在许多情况下所说的进程，实际上是指进程实体，例如，所谓创建进程，实质上是创建进程实体中的 PCB；而撤消进程，实质上是撤消进程的 PCB。</p>\n<p>(2) 动态性：</p>\n<p>进程的实质是进程实体的一次执行过程，因此，动态性是进程的最基本的特征。动态性还表现在：“它由创建而产生，由调度而执行，由撤消而消亡”。可见，进程实体有一定的生命期，而程序则只是一组有序指令的集合，并存放于某种介质上，其本身并不具有运动的含义，因而是静态的。</p>\n<p>(3) 并发性：</p>\n<p>这是指多个进程实体同存于内存中，且能在一段时间内同时运行。并发性是进程的重要特征，同时也成为 OS 的重要特征。引入进程的目的也正是为了使其进程实体能和其它进程实体并发执行；而程序(没有建立 PCB)是不能并发执行的。</p>\n<p>(4) 独立性：</p>\n<p>在传统的 OS 中，独立性是指进程实体是一个能独立运行、独立分配资源和独立接受调度的基本单位。凡未建立 PCB 的程序都不能作为一个独立的单位参与运行。</p>\n<p>(5) 异步性：</p>\n<p>这是指进程按各自独立的、 不可预知的速度向前推进，或说进程实体按异步方式运行。</p>\n<p>现在我们再来讨论进程的定义。曾有许多人从不同的角度对进程下过定义，其中较典<br>型的进程定义有：</p>\n<p>(1) 进程是程序的一次执行。</p>\n<p>(2) 进程是一个程序及其数据在处理机上顺序执行时所发生的活动。</p>\n<p>(3) 进程是程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。</p>\n<p>在引入了进程实体的概念后，我们可以把传统 OS 中的进程定义为：“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位”。</p>\n<ol start=\"2\">\n<li>进程的三种基本状态</li>\n</ol>\n<p>(1) 就绪（ready）状态：</p>\n<p>当进程已分配到除 CPU 以外的所有必要资源后，只要再获得 CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。</p>\n<p>(2) 执行状态：</p>\n<p>进程已获得 CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态；在多处理机系统中，则有多个进程处于执行状态。</p>\n<p>(3) 阻塞状态：</p>\n<p>正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态，亦即进程的执行受到阻塞，把这种暂停状态称为阻塞状态，有时也称为等待状态或封锁状态。致使进程阻塞的典型事件有：请求 I/O，申请缓冲空间等。通常将这种处于阻塞状态的进程也排成一个队列。有的系统则根据阻塞原因的不同而把处于阻塞状态的进程排成多个队列。</p>\n<p>处于就绪状态的进程，在调度程序为之分配了处理机之后，该进程便可执行，相应地，它就由就绪状态转变为执行状态。正在执行的进程也称为当前进程，如果因分配给它的时间片已完而被暂停执行时，该进程便由执行状态又回复到就绪状态；如果因发生某事件而使进程的执行受阻(例如，进程请求访问某临界资源，而该资源正被其它进程访问时)，使之无法继续执行，该进程将由执行状态转变为阻塞状态。图 2-5 示出了进程的三种基本状态以及各状态之间的转换关系。</p>\n<p><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p483\" alt=\"b7fbd2560285affd106a48c0ed12552e.png\"></p>\n<ol start=\"3\">\n<li>挂起状态</li>\n</ol>\n<p>在引入挂起状态后，又将增加从挂起状态(又称为静止状态)到非挂起状态(又称为活动状态)的转换；或者相反。可有以下几种情况：</p>\n<p>(1) 活动就绪→静止就绪。</p>\n<p>(2) 活动阻塞→静止阻塞。</p>\n<p>(3) 静止就绪→活动就绪。</p>\n<p>(4) 静止阻塞→活动阻塞。</p>\n<p><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p484\" alt=\"58e257893019bf39b8d722fdfc895135.png\"></p>\n<ol start=\"4\">\n<li>创建状态和终止状态</li>\n</ol>\n<p>(1) 创建状态：创建一个进程一般要通过两个步骤：首先，为一个新进程创建 PCB，并填写必要的管理信息；</p>\n<p>其次，把该进程转入就绪状态并插入就绪队列之中。</p>\n<p>当一个新进程被创建时，系统已为其分配了 PCB，填写了进程标识等信息，但由于该进程所必需的资源或其它信息，如主存资源尚未分配等，一般而言，此时的进程已拥有了自己的 PCB，但进程自身还未进入主存，即创建工作尚未完成，进程还不能被调度运行，其所处的状态就是创建状态。</p>\n<p>(2) 终止状态：进程的终止也要通过两个步骤：首先等待操作系统进行善后处理，然后将其 PCB 清零，并将 PCB 空间返还系统。</p>\n<p><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p485\" alt=\"6072916050ccf384b1cfd3b8c3fc0cbd.png\"></p>\n<p><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p486\" alt=\"d43fb5a4616625f5cd3b906a93a00748.png\"></p>\n<h5 id=\"2-1-4-进程控制块（PCB）\"><a href=\"#2-1-4-进程控制块（PCB）\" class=\"headerlink\" title=\"2.1.4 进程控制块（PCB）\"></a>2.1.4 进程控制块（PCB）</h5><ol>\n<li>进程控制块的作用</li>\n</ol>\n<p>为了描述和控制进程的运行，系统为每个进程定义了一个数据结构——进程控制块<br>PCB(Process Control Block)，它是进程实体的一部分，是操作系统中最重要的记型数据结构。</p>\n<p>PCB 中记录了操作系统所需的、用于描述进程的当前情况以及控制进程运行的全部信息。进程控制块的作用是使一个在多道程序环境下不能独立运行的程序(含数据)，成为一个能独立运行的基本单位，一个能与其它进程并发执行的进程。或者说，OS 是根据 PCB 来对并发执行的进程进行控制和管理的。</p>\n<p>可见，在进程的整个生命期中，系统总是通过 PCB 对进程进行控制的，亦即，系统是根据进程的 PCB 而不是任何别的什么而感知到该进程的存在的。所以说，<u>PCB 是进程存在的惟一标志。</u></p>\n<p>当系统创建一个新进程时，就为它建立了一个 PCB；进程结束时又回收其 PCB，进程于是也随之消亡。PCB 可以被操作系统中的多个模块读或修改，如被调度程序、资源分配程序、中断处理程序以及监督和分析程序等读或修改。因为 PCB 经常被系统访问，尤其是被运行频率很高的进程及分派程序访问，故 PCB 应常驻内存。系统将所有的 PCB 组织成若干个链表(或队列)，存放在操作系统中专门开辟的 PCB 区内。</p>\n<ol start=\"2\">\n<li>进程控制块中的信息</li>\n</ol>\n<p>(1) 进程标识符：</p>\n<p>进程标识符用于惟一地标识一个进程。一个进程通常有两种标识符：</p>\n<p>内部标识符。在所有的操作系统中，都为每一个进程赋予了一个惟一的数字标识符，它通常是一个进程的序号。设置内部标识符主要是为了方便系统使用。</p>\n<p>外部标识符。它由创建者提供，通常是由字母、数字组成，往往是由用户(进程)在访问该进程时使用。为了描述进程的家族关系，还应设置父进程标识及子进程标识。此外，还可设置用户标识，以指示拥有该进程的用户。</p>\n<p>(2) 处理机状态：</p>\n<p>处理机状态信息主要是由处理机的各种寄存器中的内容组成的。处理机在运行时，许多信息都放在寄存器中。当处理机被中断时，所有这些信息都必须保存在 PCB 中，以便在该进程重新执行时，能从断点继续执行。</p>\n<p>(3) 进程调度信息：</p>\n<p>在 PCB 中还存放一些与进程调度和进程对换有关的信息，包括：</p>\n<p>① 进程状态，指明进程的当前状态，作为进程调度和对换时的依据；</p>\n<p>② 进程优先级，用于描述进程使用处理机的优先级别的一个整数，优先级高的进程应优先获得处理机；</p>\n<p>③ 进程调度所需的其它信息，它们与所采用的进程调度算法有关，比如，进程已等待 CPU 的时间总和、进程已执行的时间总和等；</p>\n<p>④ 事件，指进程由执行状态转变为阻塞状态所等待发生的事件，即阻塞原因。</p>\n<p>(4) 进程控制信息：</p>\n<p>进程控制信息包括：① 程序和数据的地址，指进程的程序和数据所在的内存或外存地<br>(首)址，以便再调度到该进程执行时，能从 PCB 中找到其程序和数据；</p>\n<p>② 进程同步和通信机制，指实现进程同步和进程通信时必需的机制，如消息队列指针、信号量等，它们可能全部或部分地放在 PCB 中；</p>\n<p>③ 资源清单，即一张列出了除 CPU 以外的、进程所需的全部资源及已经分配到该进程的资源的清单；</p>\n<p>④ 链接指针，它给出了本进程(PCB)所在队列中的下一个进程的 PCB 的首地址。</p>\n<h4 id=\"2-2-进程控制\"><a href=\"#2-2-进程控制\" class=\"headerlink\" title=\"2.2 进程控制\"></a>2.2 进程控制</h4><p>进程控制一般是由 OS 的内核中的原语来实现的。</p>\n<p>原语(Primitive)是由若干条指令组成的，用于完成一定功能的一个过程。它与一般过程的区别在于：它们是“原子操作(Action Operation)”。所谓原子操作，是指一个操作中所有动作要么全做，要么全不做。换言之，它是一个不可分割的基本单位，因此，在执行过程中不允许被中断。原子操作在管态下执行，常驻内存。</p>\n<p>原语的作用是为了实现进程的通信和控制，系统对进程的控制如不使用原语，就会造成其状态的不确定性，从而达不到进程控制的目的。</p>\n<p>管态又叫特权态，系统态或核心态。CPU在管态下可以执行指令系统的全集。通常，操作系统在管态下运行。 </p>\n<p>目态又叫常态或用户态。机器处于目态时，程序只能执行非特权指令。用户程序只能在目态下运行，如果用户程序在目态下执行特权指令，硬件将发生中断，由操作系统获得控制，特权指令执行被禁止，这样可以防止用户程序有意或无意的破坏系统。</p>\n<p>从目态转换为管态的唯一途径是中断。 </p>\n<p>从管态到目态可以通过修改程序状态字来实现，这将伴随这由操作系统程序到用户程序的转换。</p>\n<h5 id=\"2-2-1-进程的创建\"><a href=\"#2-2-1-进程的创建\" class=\"headerlink\" title=\"2.2.1 进程的创建\"></a>2.2.1 进程的创建</h5><ol>\n<li>进程图</li>\n</ol>\n<p>进程图是用于描述一个进程的家族关系的有向树，如图 2-11 所示。图中的结点(圆圈)代表进程。在进程 D 创建了进程 I 之后，称 D 是 I 的父进程(Parent Process)，I 是 D 的子进程(Progeny Process)。这里可用一条由父进程指向子进程的有向边来描述它们之间的父子关系。创建父进程的进程称为祖先进程，这样便形成了一棵进程树，把树的根结点作为进程家族的祖先(Ancestor)。</p>\n<p><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p487\" alt=\"9a169c93b38c7e4e9abc02f9f6c94202.png\"></p>\n<p>了解进程间的这种关系是十分重要的。因为子进程可以继承父进程所拥有的资源，例如，继承父进程打开的文件，继承父进程所分配到的缓冲区等。当子进程被撤消时，应将其从父进程那里获得的资源归还给父进程。此外，在撤消父进程时，也必须同时撤消其所有的子进程。为了标识进程之间的家族关系，在 PCB 中都设置了家族关系表项，以标明自己的父进程及所有的子进程。</p>\n<ol start=\"2\">\n<li>引起创建进程的事件</li>\n</ol>\n<p>在多道程序环境中，只有(作为)进程(时)才能在系统中运行。因此，为使程序能运行，就必须为它创建进程。导致一个进程去创建另一个进程的典型事件，可有以下四类：</p>\n<p>(1) 用户登录。在分时系统中，用户在终端键入登录命令后，如果是合法用户，系统将为该终端建立一个进程，并把它插入就绪队列中。</p>\n<p>(2) 作业调度。在批处理系统中，当作业调度程序按一定的算法调度到某作业时，便将作业装入内存，为它分配必要的资源，并立即为它创建进程，再插入就绪队列中。</p>\n<p>(3) 提供服务。当运行中的用户程序提出某种请求后，系统将专门创建一个进程来提供用户所需要的服务，例如，用户程序要求进行文件打印，操作系统将为它创建一个打印进程，这样，不仅可使打印进程与该用户进程并发执行，而且还便于计算出为完成打印任务所花费的时间。</p>\n<p>(4) 应用请求。在上述三种情况下，都是由系统内核为它创建一个新进程；而第 4 类事件则是基于应用进程的需求，由它自己创建一个新进程，以便使新进程以并发运行方式完成特定任务。例如，某应用程序需要不断地从键盘终端输入数据，继而又要对输入数据进行相应的处理，然后，再将处理结果以表格形式在屏幕上显示。该应用进程为使这几个操作能并发执行，以加速任务的完成，可以分别建立键盘输入进程、表格输出进程。</p>\n<ol start=\"3\">\n<li>进程的创建</li>\n</ol>\n<p>一旦操作系统发现了要求创建新进程的事件后，便调用进程创建原语 Creat() 按下述步骤创建一个新进程。</p>\n<p>(1) 申请空白 PCB。为新进程申请获得惟一的数字标识符，并从 PCB 集合中索取一个空白 PCB。</p>\n<p>(2) 为新进程分配资源。为新进程的程序和数据以及用户栈分配必要的内存空间。</p>\n<p>(3) 初始化进程控制块。PCB 的初始化包括：</p>\n<p>① 初始化标识信息，将系统分配的标识符和父进程标识符填入新 PCB 中；</p>\n<p>② 初始化处理机状态信息，使程序计数器指向程序的入口地址，使栈指针指向栈顶；</p>\n<p>③ 初始化处理机控制信息，将进程的状态设置为就绪状态或静止就绪状态，对于优先级，通常是将它设置为最低优先级，除非用户以显式方式提出高优先级要求。</p>\n<p>(4) 将新进程插入就绪队列，如果进程就绪队列能够接纳新进程，便将新进程插入就绪队列。</p>\n<h5 id=\"2-2-2-进程的终止\"><a href=\"#2-2-2-进程的终止\" class=\"headerlink\" title=\"2.2.2 进程的终止\"></a>2.2.2 进程的终止</h5><ol>\n<li>进程的终止过程</li>\n</ol>\n<p>如果系统中发生了上述要求终止进程的某事件，OS 便调用进程终止原语，按下述过程<br>去终止指定的进程。</p>\n<p>(1) 根据被终止进程的标识符，从 PCB 集合中检索出该进程的 PCB，从中读出该进程的状态。</p>\n<p>(2) 若被终止进程正处于执行状态，应立即终止该进程的执行，并置调度标志为真，用于指示该进程被终止后应重新进行调度。</p>\n<p>(3) 若该进程还有子孙进程，还应将其所有子孙进程予以终止，以防它们成为不可控的进程。</p>\n<p>(4) 将被终止进程所拥有的全部资源，或者归还给其父进程，或者归还给系统。</p>\n<p>(5) 将被终止进程(PCB)从所在队列(或链表)中移出，等待其他程序来搜集信息。</p>\n<h5 id=\"2-2-3-进程的阻塞与唤醒\"><a href=\"#2-2-3-进程的阻塞与唤醒\" class=\"headerlink\" title=\"2.2.3 进程的阻塞与唤醒\"></a>2.2.3 进程的阻塞与唤醒</h5><ol>\n<li>进程阻塞过程</li>\n</ol>\n<p>正在执行的进程，当发现上述某事件时，由于无法继续执行，于是进程便通过调用阻塞原语 block 把自己阻塞。可见，进程的阻塞是进程自身的一种主动行为。进入 block过程后，由于此时该进程还处于执行状态，所以应先立即停止执行，把进程控制块中的现行状态由“执行”改为“阻塞”，并将 PCB 插入阻塞队列。如果系统中设置了因不同事件而阻塞的多个阻塞队列，则应将本进程插入到具有相同事件的阻塞(等待)队列。最后，转调度程序进行重新调度，将处理机分配给另一就绪进程并进行切换，亦即，保留被阻塞进程的处理机状态(在 PCB 中)，再按新进程的 PCB 中的处理机状态设置 CPU 的环境。</p>\n<ol start=\"2\">\n<li>进程唤醒状态</li>\n</ol>\n<p>当被阻塞进程所期待的事件出现时，如 I/O 完成或其所期待的数据已经到达，则由有关进程(比如用完并释放了该 I/O 设备的进程)调用唤醒原语 wakeup( )，将等待该事件的进程唤醒。唤醒原语执行的过程是：首先把被阻塞的进程从等待该事件的阻塞队列中移出，将其PCB 中的现行状态由阻塞改为就绪，然后再将该 PCB 插入到就绪队列中。</p>\n<p>应当指出，block 原语和 wakeup 原语是一对作用刚好相反的原语。因此，如果在某进程中调用了阻塞原语，则必须在与之相合作的另一进程中或其他相关的进程中安排唤醒原语，以能唤醒阻塞进程；否则，被阻塞进程将会因不能被唤醒而长久地处于阻塞状态，从<br>而再无机会继续运行。</p>\n<h4 id=\"2-3-进程同步\"><a href=\"#2-3-进程同步\" class=\"headerlink\" title=\"2.3 进程同步\"></a>2.3 进程同步</h4><p>在 OS 中引入进程后，虽然提高了资源的利用率和系统的吞吐量，但由于进程的异步性，也会给系统造成混乱，尤其是在他们争用临界资源时。</p>\n<p>进程同步的主要任务是对多个相关进程在执行次序上进行协调，以使并发执行的诸进程之间能有效地共享资源和相互合作，从而使程序的执行具有可再现性。</p>\n<h5 id=\"2-3-1-进程同步的基本概念\"><a href=\"#2-3-1-进程同步的基本概念\" class=\"headerlink\" title=\"2.3.1 进程同步的基本概念\"></a>2.3.1 进程同步的基本概念</h5><ol>\n<li>两种形式的制约关系：在多道程序环境下，当程序并发执行时，由于资源共享和进程合作，使同处于一个系统中的诸进程之间可能存在着以下两种形式的制约关系。</li>\n</ol>\n<p>(1) 间接相互制约关系。</p>\n<p>(2) 直接相互制约关系。</p>\n<ol start=\"2\">\n<li>临界资源</li>\n</ol>\n<p>在第一章中我们曾经介绍过，许多硬件资源如打印机、磁带机等，都属于临界资源<br>(Critical Resouce)，诸进程间应采取互斥方式，实现对这种资源的共享。（临界资源首先是共享资源）。</p>\n<ol start=\"3\">\n<li>临界区</li>\n</ol>\n<p>由前所述可知，不论是硬件临界资源，还是软件临界资源，多个进程必须互斥地对它进行访问。人们把在每个进程中访问临界资源的那段代码称为临界区(critical section)。</p>\n<ol start=\"4\">\n<li>同步机制应遵循的规则</li>\n</ol>\n<p>为实现进程互斥地进入自已的临界区，可用软件方法，更多的是在系统中设置专门的同步机构来协调各进程间的运行。所有同步机制都应遵循下述四条准则：</p>\n<p>(1) 空闲让进。当无进程处于临界区时，表明临界资源处于空闲状态，应允许一个请求进入临界区的进程立即进入自己的临界区，以有效地利用临界资源。</p>\n<p>(2) 忙则等待。当已有进程进入临界区时，表明临界资源正在被访问，因而其它试图进入临界区的进程必须等待，以保证对临界资源的互斥访问。</p>\n<p>(3) 有限等待。对要求访问临界资源的进程，应保证在有限时间内能进入自己的临界区，以免陷入“死等”状态。</p>\n<p>(4) 让权等待。当进程不能进入自己的临界区时，应立即释放处理机，以免进程陷入“忙等”状态。</p>\n<h5 id=\"2-3-2-信号量机制\"><a href=\"#2-3-2-信号量机制\" class=\"headerlink\" title=\"2.3.2 信号量机制\"></a>2.3.2 信号量机制</h5><p>信号量机构是一种功能较强的机制，可用来解决互斥与同步的问题，它只能被两个标准的原语wait(S)和signal(S)来访问，也可以记为“P操作”和“V操作”。</p>\n<h5 id=\"2-3-3-信号量的应用\"><a href=\"#2-3-3-信号量的应用\" class=\"headerlink\" title=\"2.3.3 信号量的应用\"></a>2.3.3 信号量的应用</h5><ol>\n<li><p>利用信号量实现进程互斥。</p>\n</li>\n<li><p>利用信号量实现前趋关系。</p>\n</li>\n</ol>\n<h5 id=\"2-3-4-管程机制\"><a href=\"#2-3-4-管程机制\" class=\"headerlink\" title=\"2.3.4 管程机制\"></a>2.3.4 管程机制</h5><p>虽然信号量机制是一种既方便、又有效的进程同步机制，但每个要访问临界资源的进程都必须自备同步操作 wait(S)和 signal(S)。这就使大量的同步操作分散在各个进程中。这不仅给系统的管理带来了麻烦，而且还会因同步操作的使用不当而导致系统死锁。这样，在解决上述问题的过程中，便产生了一种新的进程同步工具——管程(Monitors)。</p>\n<ol>\n<li>管程的定义</li>\n</ol>\n<p>代表共享资源的数据结构，以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序，共同构成了一个操作系统的资源管理模块，我们称之为管程。管程被请求和释放<br>资源的进程所调用。</p>\n<h4 id=\"2-4-进程通信（very-important）\"><a href=\"#2-4-进程通信（very-important）\" class=\"headerlink\" title=\"2.4 进程通信（very important）\"></a>2.4 进程通信（very important）</h4><p>进程通信，是指进程之间的信息交换，其所交换的信息量少者是一个状态或数值，多者则是成千上万个字节。进程之间的互斥和同步，由于其所交换的信息量少而被归结为低级通信。在进程互斥中，进程通过只修改信号量来向其他进程表明临界资源是否可用。</p>\n<p>应当指出，信号量机制作为同步工具是卓有成效的，但作为通信工具，则不够理想，主要表现在下述两方面：</p>\n<p>(1) 效率低，生产者每次只能向缓冲池投放一个产品(消息)，消费者每次只能从缓冲区中取得一个消息；</p>\n<p>(2) 通信对用户不透明。</p>\n<h5 id=\"2-4-1-进程通信的类型\"><a href=\"#2-4-1-进程通信的类型\" class=\"headerlink\" title=\"2.4.1 进程通信的类型\"></a>2.4.1 进程通信的类型</h5><p>目前，高级通信机制可归结为三大类：共享存储器系统、消息传递系统以及管道通信系统。</p>\n<ol>\n<li>共享存储器系统</li>\n</ol>\n<p>(1) 基于共享数据结构的通信方式。这种通信方式是低效的，只适于传递相对少量的数据。</p>\n<p>(2) 基于共享存储区的通信方式。为了传输大量数据，在存储器中划出了一块共享存储区，诸进程可通过对共享存储区中数据的读或写来实现通信。</p>\n<ol start=\"2\">\n<li>消息传递系统</li>\n</ol>\n<p>消息传递系统(Message passing system)是当前应用最为广泛的一种进程间的通信机制。在该机制中，进程间的数据交换是以格式化的消息(message)为单位的；在计算机网络中，又把 message 称为报文。程序员直接利用操作系统提供的一组通信命令(原语)，不仅能实现大量数据的传递，而且还隐藏了通信的实现细节，使通信过程对用户是透明的，从而大大减化了通信程序编制的复杂性，因而获得了广泛的应用。</p>\n<p>特别值得一提的是，在当今最为流行的微内核操作系统中，微内核与服务器之间的通信，无一例外地都采用了消息传递机制。又由于它能很好地支持多处理机系统、分布式系统和计算机网络，因此它也成为这些领域最主要的通信工具。消息传递系统的通信方式属于高级通信方式。又因其实现方式的不同而进一步分成直接通信方式和间接通信方式两种。</p>\n<ol start=\"3\">\n<li>管道通信</li>\n</ol>\n<p>所谓“管道”，是指用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件，又名 pipe 文件。向管道(共享文件)提供输入的发送进程(即写进程)，以字符流形式将大量的数据送入管道；而接受管道输出的接收进程(即读进程)，则从管道中接收(读)数据。由于发送进程和接收进程是利用管道进行通信的，故又称为管道通信。这种方式首创于UNIX 系统，由于它能有效地传送大量数据，因而又被引入到许多其它的操作系统中。</p>\n<p>为了协调双方的通信，管道机制必须提供以下三方面的协调能力：</p>\n<p>(1) 互斥，即当一个进程正在对 pipe 执行读/写操作时，其它(另一)进程必须等待。</p>\n<p>(2) 同步，指当写(输入)进程把一定数量(如 4 KB)的数据写入 pipe，便去睡眠等待，直到读(输出)进程取走数据后，再把它唤醒。当读进程读一空 pipe 时，也应睡眠等待，直至写进程将数据写入管道后，才将之唤醒。</p>\n<p>(3) 确定对方是否存在，只有确定了对方已存在时，才能进行通信。</p>\n<h4 id=\"2-5-线程\"><a href=\"#2-5-线程\" class=\"headerlink\" title=\"2.5 线程\"></a>2.5 线程</h4><h5 id=\"2-5-1-线程的基本概念\"><a href=\"#2-5-1-线程的基本概念\" class=\"headerlink\" title=\"2.5.1 线程的基本概念\"></a>2.5.1 线程的基本概念</h5><ol>\n<li>线程的引入</li>\n</ol>\n<p>如果说，在操作系统中引入进程的目的，是为了使多个程序能并发执行，以提高资源<br>利用率和系统吞吐量，那么，在操作系统中再引入线程，则是为了减少程序在并发执行时所付出的时空开销，使 OS 具有更好的并发性。</p>\n<ol start=\"2\">\n<li>线程与进程的比较</li>\n</ol>\n<p>线程具有许多传统进程所具有的特征，所以又称为轻型进程(Light-Weight Process)或进程元，相应地把传统进程称为重型进程(Heavy-Weight Process)，传统进程相当于只有一个线程的任务。在引入了线程的操作系统中，通常一个进程都拥有若干个线程，至少也有一个线程。下面我们从调度性、并发性、系统开销和拥有资源等方面对线程和进程进行比较。</p>\n<p>(1) 调度</p>\n<p>在传统的操作系统中，作为拥有资源的基本单位和独立调度、分派的基本单位都是进程。<u>而在引入线程的操作系统中，则把线程作为调度和分派的基本单位，而进程作为资源拥有的基本单位，把传统进程的两个属性分开，使线程基本上不拥有资源，这样线程便能轻装前进，从而可显著地提高系统的并发程度。</u>在同一进程中，线程的切换不会引起进程的切换，但从一个进程中的线程切换到另一个进程中的线程时，将会引起进程的切换。</p>\n<p>(2) 并发性</p>\n<p>在引入线程的操作系统中，不仅进程之间可以并发执行，而且在一个进程中的多个线程之间亦可并发执行，使得操作系统具有更好的并发性，从而能更加有效地提高系统资源的利用率和系统的吞吐量。</p>\n<p>(3) 拥有资源</p>\n<p>不论是传统的操作系统，还是引入了线程的操作系统，进程都可以拥有资源，是系统中拥有资源的一个基本单位。一般而言，线程自己不拥有系统资源(也有一点必不可少的资源)，但它可以访问其隶属进程的资源，即一个进程的代码段、数据段及所拥有的系统资源，如已打开的文件、I/O 设备等，可以供该进程中的所有线程所共享。</p>\n<p>(4) 系统开销</p>\n<p>在创建或撤消进程时，系统都要为之创建和回收进程控制块，分配或回收资源，如内存空间和 I/O 设备等，操作系统所付出的开销明显大于线程创建或撤消时的开销。</p>\n<ol start=\"3\">\n<li>线程的属性</li>\n</ol>\n<p>(1) 轻型实体。线程中的实体基本上不拥有系统资源，只是有一点必不可少的、 能保证其独立运行的资源，比如，在每个线程中都应具有一个用于控制线程运行的线程控制块TCB，用于指示被执行指令序列的程序计数器，保留局部变量、少数状态参数和返回地址等的一组寄存器和堆栈。</p>\n<p>(2) 独立调度和分派的基本单位。在多线程 OS 中，线程是能独立运行的基本单位，因而也是独立调度和分派的基本单位。由于线程很“轻”，故线程的切换非常迅速且开销小。</p>\n<p>(3) 可并发执行。在一个进程中的多个线程之间可以并发执行，甚至允许在一个进程中的所有线程都能并发执行；同样，不同进程中的线程也能并发执行。</p>\n<p>(4) 共享进程资源。在同一进程中的各个线程都可以共享该进程所拥有的资源，这首先表现在所有线程都具有相同的地址空间(进程的地址空间)。这意味着线程可以访问该地址空间中的每一个虚地址；此外，还可以访问进程所拥有的已打开文件、定时器、信号量机构等。</p>\n<h4 id=\"2-6-线程间的同步和通信\"><a href=\"#2-6-线程间的同步和通信\" class=\"headerlink\" title=\"2.6 线程间的同步和通信\"></a>2.6 线程间的同步和通信</h4><ol>\n<li>互斥锁</li>\n</ol>\n<p>互斥锁是一种比较简单的、用于实现线程间对资源互斥访问的机制。由于操作互斥锁的时间和空间开销都较低，因而较适合于高频度使用的关键共享数据和程序段。</p>\n<ol start=\"2\">\n<li>条件变量</li>\n</ol>\n<p>在许多情况下，只利用 mutex 来实现互斥访问可能会引起死锁，每一个条件变量通常都与一个互斥锁一起使用，亦即，在创建一个互斥锁时便联系着一个条件变量。单纯的互斥锁用于短期锁定，主要是用来保证对临界区的互斥进入。而条件变量则用于线程的长期等待，直至所等待的资源成为可用的资源。</p>\n<ol start=\"3\">\n<li>信号量机制</li>\n</ol>\n<p>前面所介绍的用于实现进程同步的最常用工具——信号量机制，也可用于多线程 OS中，实现诸线程或进程之间的同步。为了提高效率，可为线程和进程分别设置相应的信号量。</p>\n<h3 id=\"第三章-处理机调度与死锁\"><a href=\"#第三章-处理机调度与死锁\" class=\"headerlink\" title=\"第三章 处理机调度与死锁\"></a>第三章 处理机调度与死锁</h3><h4 id=\"3-1-调度算法\"><a href=\"#3-1-调度算法\" class=\"headerlink\" title=\"3.1 调度算法\"></a>3.1 调度算法</h4><h5 id=\"3-1-1-先来先服务和短作业-进程-优先调度算法\"><a href=\"#3-1-1-先来先服务和短作业-进程-优先调度算法\" class=\"headerlink\" title=\"3.1.1 先来先服务和短作业(进程)优先调度算法\"></a>3.1.1 先来先服务和短作业(进程)优先调度算法</h5><ol>\n<li>先来先服务调度算法</li>\n</ol>\n<p>先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。</p>\n<p>在进程调度中采用 FCFS 算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。FCFS 算法比较有利于长作业(进程)，而不利于短作业(进程)。</p>\n<ol start=\"2\">\n<li>短作业（进程）优先调度算法</li>\n</ol>\n<p>短作业(进程)优先调度算法 SJ(P)F，是指对短作业或短进程优先调度的算法。它们可以分别用于作业调度和进程调度。短作业优先(SJF)的调度算法是从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行。而短进程优先(SPF)调度算法则是从就绪队列中选出一个估计运行时间最短的进程，将处理机分配给它，使它立即执行并一直执行到完成，或发生某事件而被阻塞放弃处理机时再重新调度。</p>\n<p>SJ(P)F 调度算法也存在不容忽视的缺点：</p>\n<p>(1) 该算法对长作业不利，如作业 C 的周转时间由 10 增至 16，其带权周转时间由 2 增至 3.1。更严重的是，如果有一长作业(进程)进入系统的后备队列(就绪队列)，由于调度程序总是优先调度那些(即使是后进来的)短作业(进程)，将导致长作业(进程)长期不被调度。</p>\n<p>(2) 该算法完全未考虑作业的紧迫程度，因而不能保证紧迫性作业(进程)会被及时处理。</p>\n<p>(3) 由于作业(进程)的长短只是根据用户所提供的估计执行时间而定的，而用户又可能会有意或无意地缩短其作业的估计运行时间，致使该算法不一定能真正做到短作业优先调度。</p>\n<h5 id=\"3-1-2-高优先权优先调度算法\"><a href=\"#3-1-2-高优先权优先调度算法\" class=\"headerlink\" title=\"3.1.2 高优先权优先调度算法\"></a>3.1.2 高优先权优先调度算法</h5><ol>\n<li>优先权调度算法的类型</li>\n</ol>\n<p>为了照顾紧迫型作业，使之在进入系统后便获得优先处理，引入了最高优先权优先(FPF)调度算法。此算法常被用于批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度算法，还可用于实时系统中。当把该算法用于作业调度时，系统将从后备队列中选择若干个优先权最高的作业装入内存。当用于进程调度时，该算法是把处理机分配给就绪队列中优先权最高的进程，这时，又可进一步把该算法分成如下两种。</p>\n<p>(1) 非抢占式优先权算法</p>\n<p>在这种方式下，系统一旦把处理机分配给就绪队列中优先权最高的进程后，该进程便一直执行下去，直至完成；或因发生某事件使该进程放弃处理机时，系统方可再将处理机重新分配给另一优先权最高的进程。这种调度算法主要用于批处理系统中；也可用于某些对实时性要求不严的实时系统中。</p>\n<p>(2) 抢占式优先权调度算法</p>\n<p>在这种方式下，系统同样是把处理机分配给优先权最高的进程，使之执行。但在其执行期间，只要又出现了另一个其优先权更高的进程，进程调度程序就立即停止当前进程(原先权最高的进程)的执行，重新将处理机分配给新到的优先权最高的进程。</p>\n<p>显然，这种抢占式的优先权调度算法能更好地满足紧迫作业的要求，故而常用于要求比较严格的实时系统中，以及对性能要求较高的批处理和分时系统中。</p>\n<ol start=\"2\">\n<li>优先权的类型</li>\n</ol>\n<p>(1) 静态优先权</p>\n<p>静态优先权是在创建进程时确定的，且在进程的整个运行期间保持不变。</p>\n<p>确定进程优先权的依据有如下三个方面：</p>\n<p>① 进程类型。通常，系统进程(如接收进程、对换进程、磁盘 I/O 进程)的优先权高于一般用户进程的优先权。</p>\n<p>② 进程对资源的需求。如进程的估计执行时间及内存需要量的多少，对这些要求少的进程应赋予较高的优先权。</p>\n<p>③ 用户要求。这是由用户进程的紧迫程度及用户所付费用的多少来确定优先权的。</p>\n<p>静态优先权法简单易行，系统开销小，但不够精确，很可能出现优先权低的作业(进程)长期没有被调度的情况。因此，仅在要求不高的系统中才使用静态优先权。</p>\n<p>(2) 动态优先权</p>\n<p>动态优先权是指在创建进程时所赋予的优先权，是可以随进程的推进或随其等待时间的增加而改变的，以便获得更好的调度性能。</p>\n<ol start=\"3\">\n<li>高响应比优先调度算法</li>\n</ol>\n<p>如果我们能为每个作业引入前面所述的动态优先权，并使作业的优先级随着等待时间的增加而以速率 a 提高，则长作业在等待一定的时间后，必然有机会分配到处理机。该优先权的变化规律可描述为：</p>\n<p>优先权 = (等待时间 + 要求服务时间) / 要求服务时间</p>\n<p>由于等待时间与服务时间之和就是系统对该作业的响应时间，故该优先权又相当于响应比 RP。据此，又可表示为：</p>\n<p>RP = (等待时间 + 要求服务时间) / 要求服务时间 = 响应时间 / 要求服务时间</p>\n<p>由上式可以看出：</p>\n<p>(1) 如果作业的等待时间相同，则要求服务的时间愈短，其优先权愈高，因而该算法有利于短作业。</p>\n<p>(2) 当要求服务的时间相同时，作业的优先权决定于其等待时间，等待时间愈长，其优先权愈高，因而它实现的是先来先服务。</p>\n<p>(3) 对于长作业，作业的优先级可以随等待时间的增加而提高，当其等待时间足够长时，其优先级便可升到很高，从而也可获得处理机。</p>\n<p>简言之，该算法既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务。因此，该算法实现了一种较好的折衷。当然，在利用该算法时，每要进行调度之前，都须先做响应比的计算，这会增加系统开销。</p>\n<h5 id=\"3-1-3-基于时间片的轮转调度算法\"><a href=\"#3-1-3-基于时间片的轮转调度算法\" class=\"headerlink\" title=\"3.1.3 基于时间片的轮转调度算法\"></a>3.1.3 基于时间片的轮转调度算法</h5><p>在早期，分时系统中采用的是简单的时间片轮转法；进入 20 世纪 90年代后，广泛采用多级反馈队列调度算法</p>\n<ol>\n<li>时间片轮转法</li>\n</ol>\n<p>在早期的时间片轮转法中，系统将所有的就绪进程按先来先服务的原则排成一个队列，每次调度时，把 CPU 分配给队首进程，并令其执行一个时间片。时间片的大小从几 ms 到几百 ms。当执行的时间片用完时，由一个计时器发出时钟中断请求，调度程序便据此信号来停止该进程的执行，并将它送往就绪队列的末尾；然后，再把处理机分配给就绪队列中新的队首进程，同时也让它执行一个时间片。这样就可以保证就绪队列中的所有进程在一给定的时间内均能获得一时间片的处理机执行时间。换言之，系统能在给定的时间内响应所有用户的请求。</p>\n<ol start=\"2\">\n<li>多级反馈队列调度算法</li>\n</ol>\n<p>前面介绍的各种用作进程调度的算法都有一定的局限性。如短进程优先的调度算法，仅照顾了短进程而忽略了长进程，而且如果并未指明进程的长度，则短进程优先和基于进程长度的抢占式调度算法都将无法使用。而多级反馈队列调度算法则不必事先知道各种进程所需的执行时间，而且还可以满足各种类型进程的需要，因而它是目前被公认的一种较好的进程调度算法。在采用多级反馈队列调度算法的系统中，调度算法的实施过程如下所述。</p>\n<p>(1) 应设置多个就绪队列，并为各个队列赋予不同的优先级。第一个队列的优先级最高，第二个队列次之，其余各队列的优先权逐个降低。该算法赋予各个队列中进程执行时间片的大小也各不相同，在优先权愈高的队列中，为每个进程所规定的执行时间片就愈小。例如，第二个队列的时间片要比第一个队列的时间片长一倍，……，第 i+1 个队列的时间片要比第 i 个队列的时间片长一倍。图 3-7 是多级反馈队列算法的示意。</p>\n<p><img src=\"evernotecid://4633D8C1-4B94-48BA-9394-5D28A777C3AF/appyinxiangcom/13838219/ENResource/p488\" alt=\"5b0dd240ebd2d64e432bbec46d319bb9.png\"></p>\n<p>(2) 当一个新进程进入内存后，首先将它放入第一队列的末尾，按 FCFS 原则排队等待调度。当轮到该进程执行时，如它能在该时间片内完成，便可准备撤离系统；如果它在一个时间片结束时尚未完成，调度程序便将该进程转入第二队列的末尾，再同样地按 FCFS原则等待调度执行；如果它在第二队列中运行一个时间片后仍未完成，再依次将它放入第三队列，……，如此下去，当一个长作业(进程)从第一队列依次降到第 n 队列后，在第 n 队列中便采取按时间片轮转的方式运行。</p>\n<p>(3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第 1～(i-1)队列均空时，才会调度第 i 队列中的进程运行。如果处理机正在第 i 队列中为某进程服务时，又有新进程进入优先权较高的队列(第 1～(i-1)中的任何一个队列)，则此时新进程将抢占正在运行进程的处理机，即由调度程序把正在运行的进程放回到第 i 队列的末尾，把处理机分配给新到的高优先权进程。</p>\n<ol start=\"3\">\n<li>多级反馈队列调度算法的性能</li>\n</ol>\n<p>多级反馈队列调度算法具有较好的性能，能很好地满足各种类型用户的需要。</p>\n<p>(1) 终端型作业用户。由于终端型作业用户所提交的作业大多属于交互型作业，作业通常较小，系统只要能使这些作业(进程)在第一队列所规定的时间片内完成，便可使终端型作业用户都感到满意。</p>\n<p>(2) 短批处理作业用户。对于很短的批处理型作业，开始时像终端型作业一样，如果仅在第一队列中执行一个时间片即可完成，便可获得与终端型作业一样的响应时间。对于稍长的作业，通常也只需在第二队列和第三队列各执行一个时间片即可完成，其周转时间仍然较短。</p>\n<p>(3) 长批处理作业用户。对于长作业，它将依次在第 1，2，…，n 个队列中运行，然后再按轮转方式运行，用户不必担心其作业长期得不到处理。</p>\n<h4 id=\"3-2-实时调度\"><a href=\"#3-2-实时调度\" class=\"headerlink\" title=\"3.2 实时调度\"></a>3.2 实时调度</h4><p>由于在实时系统中都存在着若干个实时进程或任务，它们用来反应或控制某个(些)外部事件，往往带有某种程度的紧迫性，因而对实时系统中的调度提出了某些特殊要求。前面所介绍的多种调度算法并不能很好地满足实时系统对调度的要求，为此，需要引入一种新的调度，即实时调度。</p>\n<h5 id=\"3-2-1-实现实时调度的基本条件\"><a href=\"#3-2-1-实现实时调度的基本条件\" class=\"headerlink\" title=\"3.2.1 实现实时调度的基本条件\"></a>3.2.1 实现实时调度的基本条件</h5><p>1．提供必要的信息</p>\n<p>(1) 就绪时间。这是该任务成为就绪状态的起始时间，在周期任务的情况下，它就是事先预知的一串时间序列；而在非周期任务的情况下，它也可能是预知的。</p>\n<p>(2) 开始截止时间和完成截止时间。对于典型的实时应用，只须知道开始截止时间，或者知道完成截止时间。</p>\n<p>(3) 处理时间。这是指一个任务从开始执行直至完成所需的时间。在某些情况下，该时间也是系统提供的。</p>\n<p>(4) 资源要求。这是指任务执行时所需的一组资源。</p>\n<p>(5) 优先级。如果某任务的开始截止时间已经错过，就会引起故障，则应为该任务赋予“绝对”优先级；如果开始截止时间的推迟对任务的继续运行无重大影响，则可为该任务赋予“相对”优先级，供调度程序参考。</p>\n<ol start=\"2\">\n<li>处理能力强</li>\n</ol>\n<p>在实时系统中，通常都有着多个实时任务。若处理机的处理能力不够强，则有可能因处理机忙不过来而使某些实时任务不能得到及时处理，从而导致发生难以预料的后果。</p>\n<ol start=\"3\">\n<li>采用抢占式调度机制</li>\n</ol>\n<p>在含有硬实时任务的实时系统中，广泛采用抢占机制。当一个优先权更高的任务到达时，允许将当前任务暂时挂起，而令高优先权任务立即投入运行，这样便可满足该硬实时任务对截止时间的要求。但这种调度机制比较复杂。</p>\n<p>对于一些小型实时系统，如果能预知任务的开始截止时间，则对实时任务的调度可采用非抢占调度机制，以简化调度程序和对任务调度时所花费的系统开销。但在设计这种调度机制时，应使所有的实时任务都比较小，并在执行完关键性程序和临界区后，能及时地将自己阻塞起来，以便释放出处理机，供调度程序去调度那种开始截止时间即将到达的任务。</p>\n<ol start=\"4\">\n<li>具有快速切换机制</li>\n</ol>\n<p>为保证要求较高的硬实时任务能及时运行，在实时系统中还应具有快速切换机制，以保证能进行任务的快速切换。该机制应具有如下两方面的能力：</p>\n<p>(1) 对外部中断的快速响应能力。</p>\n<p>(2) 快速的任务分派能力。</p>\n<h5 id=\"3-2-2-常用的几种实时调度算法\"><a href=\"#3-2-2-常用的几种实时调度算法\" class=\"headerlink\" title=\"3.2.2 常用的几种实时调度算法\"></a>3.2.2 常用的几种实时调度算法</h5><p>1．最早截止时间优先即 EDF(Earliest Deadline First)算法</p>\n<p>该算法是根据任务的开始截止时间来确定任务的优先级。截止时间愈早，其优先级愈高。该算法要求在系统中保持一个实时任务就绪队列，该队列按各任务截止时间的早晚排序；当然，具有最早截止时间的任务排在队列的最前面。调度程序在选择任务时，总是选择就绪队列中的第一个任务，为之分配处理机，使之投入运行。最早截止时间优先算法既可用于抢占式调度，也可用于非抢占式调度方式中。</p>\n<p>2．最低松弛度优先即 LLF(Least Laxity First)算法</p>\n<p>该算法是根据任务紧急(或松弛)的程度，来确定任务的优先级。任务的紧急程度愈高，为该任务所赋予的优先级就愈高，以使之优先执行。</p>\n","categories":[],"tags":[{"name":"Operation System","path":"api/tags/Operation System.json"}]}